{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEt-Nzmi5pnU"
   },
   "source": [
    "\n",
    "# Lecture 01-1. OpenCV Overview-1 (Basic)\n",
    "\n",
    "### Contents :\n",
    "\n",
    "   1. Lecture 01-1 Overview\n",
    "   \n",
    "   2. Introducing OpenCV\n",
    "\n",
    "   3. Exploring OpenCV<br>\n",
    "     3.1. Import the OpenCV library<br>\n",
    "     3.2. Importng a simple image<br>\n",
    "     3.3. Loading videos<br>\n",
    "     3.4. Resize images<br>\n",
    "     3.5. Switching color spaces<br>\n",
    "     3.6. Saving images<br>\n",
    "     3.7. Drawing on images or videos<br>\n",
    "   \n",
    "   4. Face Detection using the OpenCV Library\n",
    "   \n",
    "   5. Think Big!\n",
    "   \n",
    "   ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TC_xSfq5pnc"
   },
   "source": [
    "### **1. Lecture 01-1 Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwt3Ub1x5pnd"
   },
   "source": [
    "This lecture aims to introduce the OpenCV library and its usage.<p>\n",
    "The intended learning outcomes are: <br>\n",
    "*   Basic understanding of OpenCV\n",
    "*   Simple OpenCV usage\n",
    "*   Relationship between OpenCV and deep learning applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5avFn2E5pnd"
   },
   "source": [
    "### **2. Introducing OpenCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxi-w9TO5pnd"
   },
   "source": [
    "OpenCV (Open Source Computer Vision Library: http://opencv.org) is an open-source library that includes several hundreds of computer vision algorithms.<p>\n",
    "\n",
    "OpenCV has a modular structure, which means that the package includes several shared or static libraries. <p>\n",
    "\n",
    "Let's take a quick look at what you can do with OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNda2Yha5pne"
   },
   "source": [
    "### **3. Exploring OpenCV**\n",
    "> **Note**: To exit the window, <span style=\"color:red\">DON’T CLICK THE RED CROSS</span>, just tap any key on your keyboard!<br>\n",
    "If you do close with the cross, you won’t let OpenCV close the box for you, and Jupyter will stay waiting, causing you to have to reset the kernel yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcxYGjad5pne"
   },
   "source": [
    "##### 3.1 Import the OpenCV library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Grg-4sPI5pnf"
   },
   "outputs": [],
   "source": [
    "# cv2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7IuorNo5pnh"
   },
   "source": [
    "##### 3.2 Importing a simple image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbni8Nqa5pni"
   },
   "source": [
    "We can read the image using the **imread** method and pass the image’s path as the only parameter.<p>\n",
    "let’s at least present the image into a new window so the user can see the result. For that, we will use **cv2.imshow** and passing the window name and the image as arguments.<p>\n",
    "Lastly, we tell Python not to exit the program until we press a key or close the window. Then we clean everything up by destroying all windows we opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "whroVqxL5pni"
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(\"./images/opencv_test.jpg\")\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "# Wait for a keypress\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-WrBtjG5pnj"
   },
   "source": [
    "##### 3.3 Loading videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoZRDcgE5pnj"
   },
   "source": [
    "OpenCV is great at dealing not only with images but also with videos. The video streams can be loaded from a video file or directly from a video source such as a webcam.<p>\n",
    "In the next example, we will load a video file and present it on a new window.<p>\n",
    "We use the method **VideoCapture** to load the video resource.<p>\n",
    "Next, we start a loop that will only end on user command, but more on that later. What’s important here is what happens **inside the loop**. The first thing we are doing is asking our VideoCapture to **read a frame of the video**. In the case of a video file, it will be the current video frame.<p>\n",
    "Now the video is playing, but there’s no way out of the while loop, so let’s build an exit strategy by detecting if the **q key** has been pressed. If it is, then we exit the loop for the cleanup activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6eK8p55E5pnk"
   },
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture(\"./images/opencv_test.mp4\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check video end\n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Video',frame)\n",
    "\n",
    "    # Wait for a keypress, Push 'q' button to close\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfgP-ydg5pnl"
   },
   "source": [
    "##### 3.4 Resizing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPidI0kj5pnl"
   },
   "source": [
    "Changing image sizes has a wide range of applications, from optimizing for sizes, zooming, or even feeding a neural network to perform some magic. If resizing an image is what you want, OpenCV got you covered.<p>\n",
    "We are scaling down the image by a factor of X (40% for the example).<p>\n",
    "The method **resize** expects at least two arguments, the image to be resized and the new dimensions (in x and y as a tuple). Optionally we can pass the third argument to define the interpolation as described on the <a href=\"https://docs.opencv.org/4.3.0/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d\">resize function docs</a>. <p>\n",
    "Let’s now see an example of how to resize an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-AjH2JCY5pnm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image Height is 236 \n",
      "Original image width is 508\n"
     ]
    }
   ],
   "source": [
    "# Scale down ratio - 40%\n",
    "scale = 40\n",
    "\n",
    "# Print image height\n",
    "print(\"Original image Height is {} \".format(img.shape[0]))\n",
    "\n",
    "# Print image width \n",
    "print(\"Original image width is {}\".format(img.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cAOQakys5pnm"
   },
   "outputs": [],
   "source": [
    "# Set the resized width\n",
    "width = int(img.shape[1] * scale / 100)\n",
    " \n",
    "# Set the resized height\n",
    "height = int(img.shape[0] * scale / 100)\n",
    "\n",
    "dim = (width, height)\n",
    "\n",
    "# Resize\n",
    "resized_img = cv2.resize(img, dim, cv2.INTER_AREA)\n",
    "\n",
    "# Display the original image\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "# Display the resized image\n",
    "cv2.imshow(\"Resized Image\", resized_img)\n",
    "\n",
    "# Wait for a keypress\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVk_Y7zU5pnn"
   },
   "source": [
    "##### 3.5 Switching color spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfYDaU5N5pnn"
   },
   "source": [
    "When we read an image with OpenCV we think of colors as channels or the depth of the image array where each channel or dimension corresponds to a color. The most common color space and the one you probably already know is **RGB**, consisting of **3 channels**: red, green, and blue.<p>\n",
    "\n",
    "Let's see the channel information of the loaded image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9cn1ksAd5pnn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel (color space info) is 3.\n"
     ]
    }
   ],
   "source": [
    "# Print image channel \n",
    "print(\"Channel (color space info) is {}.\".format(img.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai_TM-ci5pno"
   },
   "source": [
    "A more popular option for setting colors on an image is **grayscale**, where only **one channel** defines each pixel.<p>\n",
    "\n",
    "The function where all the magic happens is **cvtColor**, which expects two arguments, the image and the color space, and returns the new image without altering the original. Fortunately, OpenCV has defined values for each known color space transformation. In our case, we use **COLOR_BGR2GRAY**, which transforms **BGR to GRAY**.<p>\n",
    "\n",
    "Let’s see an example of how we can transform a color image into a greyscale one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rfFnS16R5pno"
   },
   "outputs": [],
   "source": [
    "# Convert BGR to Gray\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the switched color space image as gray\n",
    "cv2.imshow(\"Gray\", gray_img)\n",
    "\n",
    "# Wait for a keypress\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rso_cHaT5pnp"
   },
   "source": [
    "##### 3.6 Saving images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbKJv6Wc5pnp"
   },
   "source": [
    "You can see that we’ve used a function called **imwrite** responsible for saving images in our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "riXVJNMi5pnp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "합계 8\r\n",
      "drwxr-xr-x 2 root  root  4096 12월  8 00:45 .\r\n",
      "drwxrwxr-x 5 linux linux 4096 12월  8 00:45 ..\r\n"
     ]
    }
   ],
   "source": [
    "# Save converted gray image\n",
    "cv2.imwrite(\"SAVE/image_gray.jpg\", gray_img)\n",
    "\n",
    "# Save original image\n",
    "cv2.imwrite(\"SAVE/image_original.jpg\", img)\n",
    "\n",
    "# Check if image files are created\n",
    "!mkdir -p ./SAVE\n",
    "!ls -la ./SAVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvvnvl745pnp"
   },
   "source": [
    "##### 3.7 Drawing on images or videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzpTAhMA5pnq"
   },
   "source": [
    "So far, we have been playing with the images without adding anything new to them. It’s time we change that. OpenCV allows us not only to perform transformations and effects to the images but to change them or draw on them.<p>\n",
    "\n",
    "Drawing on images can be useful if, for example, you are trying to make an object tracking program or face recognition program where you want to draw a square or shape to highlight the identified objects.<p>\n",
    "\n",
    "**Drawing a rectangle**<p>\n",
    "\n",
    "Rectangles are the most used shape, at least in the AI world, as they are commonly used to track objects like faces, cars, or traffic signs on the images.<p>\n",
    "\n",
    "The **rectangle** function expects the image and four more arguments: the top-left corner of the rectangle in (x1, y1), the bottom-right of it in (x2, y2), the line’s color (in BGR for our image), and its thickness in pixels.<p>\n",
    "\n",
    "Let’s draw a rectangle on images to show how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EIkz3ERF5pnr"
   },
   "outputs": [],
   "source": [
    "# X1, Y1\n",
    "POS1 = (200, 100)\n",
    "\n",
    "# X2, Y2\n",
    "POS2 = (400,200)\n",
    "\n",
    "# Line color (B, G, R)\n",
    "COLOR = (0, 0, 255)\n",
    "\n",
    "# Thickness in pixels\n",
    "T = 5\n",
    "\n",
    "# Drawing a rectangle to the original image\n",
    "rect_img = cv2.rectangle(img, POS1, POS2, COLOR, T)\n",
    "\n",
    "# Display the resized image\n",
    "cv2.imshow(\"Drawing rectangle on Image\", rect_img)\n",
    "\n",
    "# Wait for a keypress\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNQmkG--5pnr"
   },
   "source": [
    "**Drawing a circle**<p>\n",
    "\n",
    "The **circle** function that expects the image and four more arguments: the center point of the circle in (x, y), the radius in pixels, the color of it, and the line thickness.<p>\n",
    "Let’s draw a circle on video frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "I3wDDqBp5pns"
   },
   "outputs": [],
   "source": [
    "# Center - X, Y\n",
    "POS = (300, 200)\n",
    "\n",
    "# Radius\n",
    "RADIUS = 100\n",
    "\n",
    "# Line color (B, G, R)\n",
    "COLOR = (0, 0, 255)\n",
    "\n",
    "# Thickness in pixels\n",
    "T = 5\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(\"./images/opencv_test.mp4\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check video end\n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    # Drawing a circle on video frame\n",
    "    circle_frame = cv2.circle(frame, POS, RADIUS, COLOR, T)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Drawing circle on video frame', circle_frame)\n",
    "\n",
    "    # Wait for a keypress, Push 'q' button to close\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJQppEwm5pns"
   },
   "source": [
    "### **4. Face Detection using the OpenCV Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw5eRppq5pnt"
   },
   "source": [
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.<p>\n",
    "\n",
    "Here we will work with face detection. Initially, the algorithm needs a lot of positive images (images of faces) and negative images (images without faces) to train the classifier. Then we need to extract features from it. For this, Haar features shown in the below image are used. They are just like our convolutional kernel. Each feature is a single value obtained by subtracting sum of pixels under the white rectangle from sum of pixels under the black rectangle.<p>\n",
    "\n",
    "![casecade](./images/cascade.jpg)\n",
    "\n",
    "In this tutorial, you will learn **how simple** it is to implement facial recognition using the **OpenCV library** (CascadeClassifier).<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SSb_jOZU5pnt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Library path\n",
    "cascPath = \"./images/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(\"./images/opencv_test.mp4\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    # Convert BGR to Gray\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,     # 이미지에서 얼굴 크기가 서로 다른 것을 보상해주는 값\n",
    "        minNeighbors=5,    # 얼굴 사이의 최소 간격(픽셀)입니다\n",
    "        minSize=(30, 30),   # 얼굴의 최소 크기입니다\n",
    "    )\n",
    "    \n",
    "    # 검출된 얼굴 주변에 사각형 그리기\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Face Detected Video', frame)\n",
    "\n",
    "    # Wait for a keypress, Push 'q' button to close\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4mj0lSL5pnu"
   },
   "source": [
    "### **5. Think Big!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPTdOpkx5pnv"
   },
   "source": [
    "Instead of using the OpenCV library, what do you think is going to happen if the face detection section was done by inference using a Neural Network created through deep learning training?<p>\n",
    "    \n",
    "![thinkbig](./images/think.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ufrBLd2nypS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day1_L01_1 - OpenCV_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
